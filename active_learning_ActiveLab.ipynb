{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Active Learning with Multiple Data Annotators via ActiveLab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/cleanlab/examples/blob/master/active_learning_multiannotator/active_learning.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates a practical approach to active learning for training classification models with cleanlab. You can run this same code with *any* classifier model for any data type (image, text, tabular, audio, etc).\n",
    "\n",
    "In active learning, we aim to construct a labeled dataset by collecting the fewest labels that still allow us to train an accurate classifier model. Here we assume data labeling is done in **batches**, and between these data labeling rounds, we retrain our classifier and combine it with an [ActiveLab algorithm](https://arxiv.org/abs/2301.11856) that decides which examples (i.e. datapoints) would be most informative to label next round. We assume there are **multiple** annotators to label the data, but since their labels are not necessarily perfect, we sometimes wish to ask a new annotator to provide an extra label for a previously labeled example. This active learning with multiple annotators setup is more widely applicable than academic studies which only consider labeling one example in each round or being limited to a single (noise-free) annotation per example. The code demonstrated here still works effectively in single annotator settings too!\n",
    "\n",
    "cleanlab provides two useful estimates for multi-annotator active learning: (1) an active learning score estimating how informative an additional label would be for each example, (2) accurate consensus labels for the previously labeled examples that can be used for classifier model training.\n",
    "\n",
    "This notebook demonstrates how to use these estimates for sequential active learning, showing how a classification model iteratively improves after (re)labeling examples for multiple rounds. Some examples in the initial dataset are allowed to have been labeled by multiple annotators, while other examples may have 0 labels (unlabeled pool). Cleanlab's active learning score indicates whether you should collect: another label for an already-labeled example (ie. having one more annotator review some potentially difficult example), or the first label for a new example that has not yet been labeled. The active learning scores properly weigh this trade-off based on cleanlab's estimates of label quality, in order to maximally improve your classifier with the fewest total labels.\n",
    "\n",
    "This notebook implements the following steps:\n",
    "\n",
    "1. Establish consensus labels (for the already labeled data). Use them to train a classifier model and then obtain out-of-sample predicted probabilities for each example.\n",
    "2. Compute active learning scores for every example, which estimate our current confidence in knowing its true label.\n",
    "3. Collect additional labels for the examples with the lowest active learning scores. These are the most potentially informative examples whose true label we are least certain of. \n",
    "4. Repeat the steps above to collect as many labels as your budget permits.\n",
    "\n",
    "The accuracy of the model trained on the resulting dataset will generally match that of the same model trained on a much larger set of randomly collected labels. I.e. this is the most cost-effective way to train an accurate classifier!\n",
    "\n",
    "In this example we use a modified version of the [Wall-Following Robot Navigation](https://www.openml.org/search?type=data&sort=runs&status=any&qualities.NumberOfClasses=gte_2&qualities.NumberOfInstances=between_1000_10000&id=1526) dataset, with multiple data annotators who each provide noisy labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dependencies and get data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please install the dependencies specified in this [requirements.txt](https://github.com/cleanlab/examples/blob/master/active_learning_multiannotator/requirements.txt) file before running the notebook.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from cleanlab.multiannotator import get_majority_vote_label, get_label_quality_multiannotator, get_active_learning_scores\n",
    "\n",
    "from utils.model_training import fit_predict_proba\n",
    "from utils.active_learning import setup_next_iter_data, add_new_annotator\n",
    "from data_processing.read_data import generate_MAPAL_data,generate_new_data,generate_ActiveLab_MAPAL_data,generate_new_data_ActiveLab\n",
    "import torch\n",
    "import random\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget -nc 'https://cleanlab-public.s3.amazonaws.com/ActiveLearning/WallRobot/data.tar.gz'\n",
    "# !tar -xf data.tar.gz data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the following datafiles:\n",
    "\n",
    "- `multiannotator_labels` is a DataFrame that contains labels from multiple annotators for each example (different number of annotations per example)\n",
    "- `X_labeled` are the features for the examples that have been labeled by at least one annotator\n",
    "- `X_unlabeled` are the features for the examples that have not yet been labeled by any annotator\n",
    "\n",
    "Additionally, we load some extra files for demo purposes, which will probably not be available in your application:\n",
    "\n",
    "- `extra_labels_labeled` and `extra_labels_unlabeled` are sampled from when we get ask annotators to provide additional labels later in this notebook\n",
    "- `X_test` and `true_labels_test` are used to measure the current model's predictive accuracy in each round of multi-annotator active learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed set as 1\n",
      "Knowledge Base Results directory path :  results/Knowledge_Base/vehicle-simulated-x-0.4-0.95-0.7\n",
      "Knowledge Base Results directory path :  data_processing\\vehicle-simulated-x-0.4\n"
     ]
    }
   ],
   "source": [
    "def set_seed(seed: int = 42) -> None:  ## Set SEEDS FUNCTION\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    # torch.cuda.manual_seed(seed)\n",
    "    # When running on the CuDNN backend, two further options must be set\n",
    "    # torch.backends.cudnn.deterministic = True\n",
    "    # torch.backends.cudnn.benchmark = False\n",
    "    # Set a fixed value for the hash seed\n",
    "    # os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    print(f\"Random seed set as {seed}\")\n",
    "\n",
    "\n",
    "Dataset = \"vehicle-simulated-x\"\n",
    "\n",
    "Data_folder_path = \"datasets\"\n",
    "\n",
    "Data_path = Data_folder_path + \"/\" + Dataset + \".csv\"\n",
    "\n",
    "\n",
    "budget = 0.4\n",
    "test_ratio = 0.4\n",
    "boot_size = 0.4\n",
    "s_t = 0.95 # SIMILARITY THRESHOLD --- 1 (check)\n",
    "w_t = 0.7 # WEIGHT THRESHOLD ---- 1 (check)\n",
    "\n",
    "seed = 1\n",
    "set_seed(seed)\n",
    "\n",
    "\n",
    "parent_dir_1 = \"results/Knowledge_Base/\"\n",
    "dir_name_1 = Dataset + \"-\"+str(budget) + \"-\" + str(s_t) + \"-\" + str(w_t)\n",
    "\n",
    "Path_results = os.path.join(parent_dir_1,dir_name_1)\n",
    "if not os.path.isdir(Path_results):\n",
    "    os.mkdir(Path_results)\n",
    "print(\"Knowledge Base Results directory path : \",Path_results)\n",
    "\n",
    "parent_dir_2 = \"data_processing\"\n",
    "dir_name_2 = Dataset + \"-\" + str(budget)\n",
    "Path_mapal_data = os.path.join(parent_dir_2,dir_name_2)\n",
    "if not os.path.isdir(Path_mapal_data):\n",
    "    os.mkdir(Path_mapal_data)\n",
    "print(\"Knowledge Base Results directory path : \",Path_mapal_data)\n",
    "\n",
    "#specify path for export text file\n",
    "txt_path = Path_results +\"/comparison.txt\"\n",
    "\n",
    "with open(txt_path, 'a') as f:\n",
    "    f.write(Dataset+\"\\n\")\n",
    "    f.write(\"Budget : \"+str(budget)+\"\\n\")\n",
    "    f.write(\"Similarity Threshold : \"+str(s_t)+\"\\n\")\n",
    "    f.write(\"Weight Threshold : \"+str(w_t)+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train features shape, Train labels shape, Train Annotator Labels shape\n",
      "(507, 18) (507,) (507, 4)\n",
      "Validation features Shape, Validation labels shape, Validation Annotators Label shape\n",
      "(339, 18) (339,) (339, 4)\n",
      "(507, 18) (507,) (507, 4)\n",
      "boot up (array([0, 1, 2, 3], dtype=int64), array([54, 48, 52, 48], dtype=int64)) 202\n",
      "active up (array([0, 1, 2, 3], dtype=int64), array([82, 72, 79, 72], dtype=int64))\n",
      "valid up (array([0, 1, 2, 3], dtype=int64), array([82, 92, 86, 79], dtype=int64))\n",
      "Boot Data Features shape, Boot Data Labels shape, Boot Data Annotator Labels shape\n",
      "(202, 18) (202,) (202, 4)\n",
      "Active Data Features shape, Active Data Labels shape, Active Data Annotator Labels shape\n",
      "(305, 18) (305,) (305, 4)\n",
      "MAPAL budget :  206\n",
      "Boot budget :  202\n",
      "Our Budget :  4\n"
     ]
    }
   ],
   "source": [
    "# RUN CELL TO GENERATE FRESH DATA\n",
    "TRAIN, VAL, BOOT, ACTIVE, budget = generate_new_data_ActiveLab(Data_path,budget,test_ratio=test_ratio,boot_size = boot_size, seed = seed)\n",
    "x_train, y_train, y_annot_train = TRAIN\n",
    "x_val, y_val, y_annot_val = VAL\n",
    "x_boot, y_boot, y_annot_boot = BOOT\n",
    "x_active, y_active, y_annot_active = ACTIVE\n",
    "m = y_annot_active.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train features shape, Train labels shape, Train Annotator Labels shape\n",
      "(507, 18) (507,) (507, 4)\n",
      "Validation features Shape, Validation labels shape, Validation Annotators Label shape\n",
      "(339, 18) (339,) (339, 4)\n",
      "(507, 18) (507,) (507, 4)\n",
      "boot up (array([0, 1, 2, 3], dtype=int64), array([54, 48, 52, 48], dtype=int64)) 202\n",
      "active up (array([0, 1, 2, 3], dtype=int64), array([82, 72, 79, 72], dtype=int64))\n",
      "valid up (array([0, 1, 2, 3], dtype=int64), array([82, 92, 86, 79], dtype=int64))\n",
      "Boot Data Features shape, Boot Data Labels shape, Boot Data Annotator Labels shape\n",
      "(202, 18) (202,) (202, 4)\n",
      "Active Data Features shape, Active Data Labels shape, Active Data Annotator Labels shape\n",
      "(305, 18) (305,) (305, 4)\n",
      "MAPAL budget :  812\n",
      "Boot budget :  202\n",
      "Our active Budget :  610\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>train-micro-misclf-rate</th>\n",
       "      <th>test-micro-misclf-rate</th>\n",
       "      <th>train-macro-misclf-rate</th>\n",
       "      <th>test-macro-misclf-rate</th>\n",
       "      <th>n-labeled-samples</th>\n",
       "      <th>n-true-labels-0</th>\n",
       "      <th>n-false-labels-0</th>\n",
       "      <th>n-true-labels-1</th>\n",
       "      <th>n-false-labels-1</th>\n",
       "      <th>n-true-labels-2</th>\n",
       "      <th>n-false-labels-2</th>\n",
       "      <th>n-true-labels-3</th>\n",
       "      <th>n-false-labels-3</th>\n",
       "      <th>n-true-labels</th>\n",
       "      <th>n-false-labels</th>\n",
       "      <th>times</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.761341</td>\n",
       "      <td>0.766962</td>\n",
       "      <td>0.754494</td>\n",
       "      <td>0.787445</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.741617</td>\n",
       "      <td>0.746313</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.741617</td>\n",
       "      <td>0.746313</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.741617</td>\n",
       "      <td>0.746313</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.741617</td>\n",
       "      <td>0.746313</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808</th>\n",
       "      <td>808</td>\n",
       "      <td>0.264300</td>\n",
       "      <td>0.392330</td>\n",
       "      <td>0.266953</td>\n",
       "      <td>0.376147</td>\n",
       "      <td>507</td>\n",
       "      <td>279</td>\n",
       "      <td>159</td>\n",
       "      <td>64</td>\n",
       "      <td>33</td>\n",
       "      <td>55</td>\n",
       "      <td>29</td>\n",
       "      <td>147</td>\n",
       "      <td>42</td>\n",
       "      <td>545</td>\n",
       "      <td>263</td>\n",
       "      <td>0.002328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>809</th>\n",
       "      <td>809</td>\n",
       "      <td>0.264300</td>\n",
       "      <td>0.389381</td>\n",
       "      <td>0.266778</td>\n",
       "      <td>0.373619</td>\n",
       "      <td>507</td>\n",
       "      <td>279</td>\n",
       "      <td>159</td>\n",
       "      <td>65</td>\n",
       "      <td>33</td>\n",
       "      <td>55</td>\n",
       "      <td>29</td>\n",
       "      <td>147</td>\n",
       "      <td>42</td>\n",
       "      <td>546</td>\n",
       "      <td>263</td>\n",
       "      <td>0.002612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810</th>\n",
       "      <td>810</td>\n",
       "      <td>0.264300</td>\n",
       "      <td>0.395280</td>\n",
       "      <td>0.266778</td>\n",
       "      <td>0.379006</td>\n",
       "      <td>507</td>\n",
       "      <td>279</td>\n",
       "      <td>159</td>\n",
       "      <td>65</td>\n",
       "      <td>33</td>\n",
       "      <td>56</td>\n",
       "      <td>29</td>\n",
       "      <td>147</td>\n",
       "      <td>42</td>\n",
       "      <td>547</td>\n",
       "      <td>263</td>\n",
       "      <td>0.002663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>811</th>\n",
       "      <td>811</td>\n",
       "      <td>0.264300</td>\n",
       "      <td>0.398230</td>\n",
       "      <td>0.266778</td>\n",
       "      <td>0.381913</td>\n",
       "      <td>507</td>\n",
       "      <td>279</td>\n",
       "      <td>159</td>\n",
       "      <td>66</td>\n",
       "      <td>33</td>\n",
       "      <td>56</td>\n",
       "      <td>29</td>\n",
       "      <td>147</td>\n",
       "      <td>42</td>\n",
       "      <td>548</td>\n",
       "      <td>263</td>\n",
       "      <td>0.002655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812</th>\n",
       "      <td>812</td>\n",
       "      <td>0.268245</td>\n",
       "      <td>0.398230</td>\n",
       "      <td>0.270525</td>\n",
       "      <td>0.381913</td>\n",
       "      <td>507</td>\n",
       "      <td>279</td>\n",
       "      <td>159</td>\n",
       "      <td>66</td>\n",
       "      <td>34</td>\n",
       "      <td>56</td>\n",
       "      <td>29</td>\n",
       "      <td>147</td>\n",
       "      <td>42</td>\n",
       "      <td>548</td>\n",
       "      <td>264</td>\n",
       "      <td>0.002427</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>813 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index  train-micro-misclf-rate  test-micro-misclf-rate  \\\n",
       "0        0                 0.761341                0.766962   \n",
       "1        1                 0.741617                0.746313   \n",
       "2        2                 0.741617                0.746313   \n",
       "3        3                 0.741617                0.746313   \n",
       "4        4                 0.741617                0.746313   \n",
       "..     ...                      ...                     ...   \n",
       "808    808                 0.264300                0.392330   \n",
       "809    809                 0.264300                0.389381   \n",
       "810    810                 0.264300                0.395280   \n",
       "811    811                 0.264300                0.398230   \n",
       "812    812                 0.268245                0.398230   \n",
       "\n",
       "     train-macro-misclf-rate  test-macro-misclf-rate  n-labeled-samples  \\\n",
       "0                   0.754494                0.787445                  0   \n",
       "1                   0.750000                0.750000                  1   \n",
       "2                   0.750000                0.750000                  1   \n",
       "3                   0.750000                0.750000                  1   \n",
       "4                   0.750000                0.750000                  1   \n",
       "..                       ...                     ...                ...   \n",
       "808                 0.266953                0.376147                507   \n",
       "809                 0.266778                0.373619                507   \n",
       "810                 0.266778                0.379006                507   \n",
       "811                 0.266778                0.381913                507   \n",
       "812                 0.270525                0.381913                507   \n",
       "\n",
       "     n-true-labels-0  n-false-labels-0  n-true-labels-1  n-false-labels-1  \\\n",
       "0                  0                 0                0                 0   \n",
       "1                  0                 0                1                 0   \n",
       "2                  1                 0                1                 0   \n",
       "3                  1                 0                1                 0   \n",
       "4                  1                 0                1                 0   \n",
       "..               ...               ...              ...               ...   \n",
       "808              279               159               64                33   \n",
       "809              279               159               65                33   \n",
       "810              279               159               65                33   \n",
       "811              279               159               66                33   \n",
       "812              279               159               66                34   \n",
       "\n",
       "     n-true-labels-2  n-false-labels-2  n-true-labels-3  n-false-labels-3  \\\n",
       "0                  0                 0                0                 0   \n",
       "1                  0                 0                0                 0   \n",
       "2                  0                 0                0                 0   \n",
       "3                  0                 1                0                 0   \n",
       "4                  0                 1                1                 0   \n",
       "..               ...               ...              ...               ...   \n",
       "808               55                29              147                42   \n",
       "809               55                29              147                42   \n",
       "810               56                29              147                42   \n",
       "811               56                29              147                42   \n",
       "812               56                29              147                42   \n",
       "\n",
       "     n-true-labels  n-false-labels     times  \n",
       "0                0               0  0.000000  \n",
       "1                1               0  0.000098  \n",
       "2                2               0  0.000130  \n",
       "3                2               1  0.000130  \n",
       "4                3               1  0.000132  \n",
       "..             ...             ...       ...  \n",
       "808            545             263  0.002328  \n",
       "809            546             263  0.002612  \n",
       "810            547             263  0.002663  \n",
       "811            548             263  0.002655  \n",
       "812            548             264  0.002427  \n",
       "\n",
       "[813 rows x 17 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## RUN CELL TO USE MAPAL GENERATED DATA\n",
    "\n",
    "TRAIN, VAL, BOOT, ACTIVE, instance_annotator_pair, Mapal_Data, ordered_instances, budget, MAPAL_results_path = generate_ActiveLab_MAPAL_data(Path_mapal_data,boot_size,seed)\n",
    "x_train, y_train, y_annot_train = TRAIN\n",
    "x_val, y_val, y_annot_val = VAL\n",
    "x_boot, y_boot, y_annot_boot = BOOT\n",
    "x_active, y_active, y_annot_active = ACTIVE\n",
    "m = y_annot_active.shape[1]\n",
    "new_x_train,new_y_train,new_y_annot_train = Mapal_Data\n",
    "Mapal_Data_Frame = pd.read_csv(MAPAL_results_path)\n",
    "Mapal_Data_Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# biodegradation -0.2\n",
    "# num_rounds = 10\n",
    "# batch_size_to_label = 38\n",
    "\n",
    "# ionosphere -0.4, seeds - 0.4\n",
    "# num_rounds = 12\n",
    "# batch_size_to_label = 21\n",
    "\n",
    "# reports-mozilla - 0.2\n",
    "# num_rounds = 12\n",
    "# batch_size_to_label = 20\n",
    "\n",
    "# medical - 0.4\n",
    "# num_rounds = 15\n",
    "# batch_size_to_label = 23\n",
    "\n",
    "# iris - 0.4\n",
    "# num_rounds = 12\n",
    "# batch_size_to_label = 12\n",
    "\n",
    "# Vehicle - 0.4\n",
    "num_rounds = 10\n",
    "batch_size_to_label = 61"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels :  [0 1 2 3]\n",
      "Frequency :  [82 92 86 79]\n",
      "(202, 4)\n"
     ]
    }
   ],
   "source": [
    "labels, frequency = np.unique(y_val,return_counts=True)\n",
    "print('Labels : ',labels)\n",
    "print('Frequency : ',frequency)\n",
    "num_class = len(labels)\n",
    "\n",
    "multiannotator_labels = np.empty(y_annot_boot.shape)\n",
    "multiannotator_labels.fill(np.NaN)\n",
    "print(multiannotator_labels.shape)\n",
    "for i in range(multiannotator_labels.shape[0]):\n",
    "    idx = np.random.randint(m)\n",
    "    multiannotator_labels[i][idx] = y_annot_boot.iloc[i][idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiannotator_labels = pd.DataFrame(multiannotator_labels)\n",
    "X_labeled = x_boot.to_numpy()\n",
    "X_unlabeled = x_active.to_numpy()\n",
    "\n",
    "extra_labels_labeled = y_annot_boot.to_numpy()\n",
    "extra_labels_unlabeled = y_annot_active.to_numpy()\n",
    "X_test = x_val.to_numpy()\n",
    "true_labels_test = y_val.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_labeled shape :  (202, 18)\n",
      "X_unlabeled shape :  (305, 18)\n",
      "multiannotator_labels shape :  (202, 4)\n",
      "extra_labels_labeled shape :  (202, 4)\n",
      "extra_labels_unlabeled shape :  (305, 4)\n"
     ]
    }
   ],
   "source": [
    "print('X_labeled shape : ',X_labeled.shape)\n",
    "print('X_unlabeled shape : ',X_unlabeled.shape)\n",
    "print('multiannotator_labels shape : ',multiannotator_labels.shape)\n",
    "print('extra_labels_labeled shape : ',extra_labels_labeled.shape)\n",
    "print('extra_labels_unlabeled shape : ',extra_labels_unlabeled.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model to obtain predicted probabilites\n",
    "\n",
    "First, we train our model on a set of consensus labels obtained using majority vote to get the out-of-sample predicted class probabilities for both the labeled and unlabeled data. Note that the `multiannotator_labels` DataFrame used to obtain consensus labels only includes the examples that have been labeled by at least one annotator, as we are not able to get consensus labels for examples that have not been labeled at all.\n",
    "\n",
    "The function will return two sets of predicted probabilites, `pred_probs_labeled` are the predicted probabilites for examples that have existing annotator labels (they correspond directly with the features `X_labeled`), whereas `active_learning_scores_unlabeled` are the predicted probabilites for examples that do not have any annotator labels (they correspond directly with the features `X_unlabeled`). These predicted probabilities will later be used to compute the active learning score.\n",
    "\n",
    "If working with your own dataset, you should consider modifying this `fit_predict_proba` function so that it is better fitted for training your specific dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get current consensus labels\n",
    "consensus_labels = get_majority_vote_label(multiannotator_labels)\n",
    "\n",
    "# Train model to get out-of-sample predicted probabilies for both labels and unlabeled data\n",
    "pred_probs_labeled, pred_probs_unlabeled = fit_predict_proba(\n",
    "    ExtraTreesClassifier(),\n",
    "    X_labeled,\n",
    "    consensus_labels,\n",
    "    cv_n_folds=num_class,\n",
    "    X_unlabeled=X_unlabeled,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain active learning scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will get the active learning scores for each datapoint (both labeled and unlabeled) by using a combination of the annotators' agremeent and model confidence. These scores represent how confident we are about an example's true label based on the currently obtained annotations; examples with the lowest scores are those for which additional labels should be collected (i.e. likely the most informative). These scores are estimated via an **ActiveLab** algorithm developed by the Cleanlab team, and may sometimes prioritize an already-labeled example over an unlabeled example if the annotations for the labeled example are deemed unreliable (ActiveLab appropriately estimates the value of collecting new annotations for unlabeled data vs already-labeled data). \n",
    "\n",
    "Similar to above, the `multiannotator_labels` DataFrame here should only include examples that have received at least one annotation (`multiannotator_labels` should have the same number of rows as `pred_probs_labeled`). This method returns two arrays: `active_learning_scores` represents the scores for examples with existing annotations, and `active_learning_scores_unlabeled` represents the scores for examples with no annotations so far. Scores should be directly comparable between these two groups, and you should favor collecting an additional label for the examples with the lowest scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_learning_scores, active_learning_scores_unlabeled = get_active_learning_scores(\n",
    "    multiannotator_labels, pred_probs_labeled, pred_probs_unlabeled\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.53777778, 0.51111111, 0.36444444, 0.47111111, 0.69777778])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample of active learning scores\n",
    "active_learning_scores[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get index to relabel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we can ranks the examples by their active learning scores, and obtain the index of the examples with the lowest scores; these are the least confident examples which we will want to collect more labels for.\n",
    "\n",
    "The code cell below shows how to combine the labeled and unlabeled examples before ranking them and obtaining their respective indices to collect more labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size_to_label = 21 # you can pick how many examples to collect more labels for at each round\n",
    "\n",
    "num_labeled = len(active_learning_scores)\n",
    "active_learning_scores_combined = np.concatenate((active_learning_scores, active_learning_scores_unlabeled))\n",
    "\n",
    "to_label_idx_combined = np.argsort(active_learning_scores_combined)[:batch_size_to_label]\n",
    "to_label_idx_labeled = to_label_idx_combined[to_label_idx_combined < num_labeled]\n",
    "to_label_idx_unlabeled = (to_label_idx_combined[to_label_idx_combined >= num_labeled] - num_labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10, 19, 15,  7,  8,  5, 24, 29, 12, 20, 26, 21], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample of indices to collect more labels for\n",
    "to_label_idx_labeled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Bringing Your Own Data (BYOD)?\n",
    "> \n",
    "> You can easily replace the above with your own dataset, and obtain the active learning scores and indices to collect more labels for using the code above.\n",
    "> \n",
    "> `multiannotator_labels` should be a numpy array of pandas DataFrame where each column represents an annotator and each row represents an example. The classes should be ingeters from 0 to num_classes - 1, where examples that were not labeled by a particular annotator are represented using `np.nan`. `multiannotator_labels` should also only contain the examples that have been labeled by at least one annotator (no row should consist of only `np.nan` values).\n",
    "> \n",
    "> `X_labeled` and `X_unlabeled` should be numpy arrays that have the same number of columns. However, if you do not have any unlabeled examples, you can also pass an empty array of `None` as the value of `X_unlabeled`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving model accuracy over 15 rounds of multi-annotator active learning (collecting new labels) \n",
    "\n",
    "The code below shows a full demonstration of how we can repeatedly use the functions demonstrated above for multiple rounds in order to select which examples to collect new labels for, ask annotators to provide these new labels (via a noisy simulation in this example), and use the newly collected labels to get improved consensus labels used to train an improved classification model.\n",
    "\n",
    "This demonstration runs this multi-annotator active learning loop for 15 rounds, choosing 100 examples to collect more labels for each round. Each round, we use the consensus labels of each labeled example to train a classifier (here we used an `ExtraTrees` classifier) and obtain out-of-sample predicted probabilites, which is then used to compute the active learning scores for every example. We then synthetically collect new labels (this process is meant to simulate getting a new annotator to annotated a selection of examples) and repeat the active learning loop. \n",
    "\n",
    "For the first round of training, we obtain consensus labels using majority vote as we do not have any predicted probabilites yet. For subsequent rounds, we employ the classifier-predicted probabilites for each example (obtained from the previous round) with cleanlab's [CROWDLAB algorithm](https://docs.cleanlab.ai/stable/tutorials/multiannotator.html), in order to produce higher quality consensus labels that the model can be trained with.\n",
    "\n",
    "[Optional step] We also measure the model performance on a test set each round to demonstrate the improvement of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get indices of examples with the lowest active learning score to collect more labels for\n",
    "def get_idx_to_label(\n",
    "    active_learning_scores,\n",
    "    batch_size_to_label,\n",
    "    active_learning_scores_unlabeled=None,\n",
    "):\n",
    "    if active_learning_scores_unlabeled is None:\n",
    "        active_learning_scores_unlabeled = np.array([])\n",
    "\n",
    "    num_labeled = len(active_learning_scores)\n",
    "    active_learning_scores_combined = np.concatenate((active_learning_scores, active_learning_scores_unlabeled))\n",
    "\n",
    "    if batch_size_to_label > len(active_learning_scores_combined):\n",
    "        raise ValueError(\"num_examples_to_relabel is larger than the total number of examples available\")\n",
    "\n",
    "    to_label_idx_combined = np.argsort(active_learning_scores_combined)[:batch_size_to_label]\n",
    "    to_label_idx = to_label_idx_combined[to_label_idx_combined < num_labeled]\n",
    "    to_label_idx_unlabeled = (to_label_idx_combined[to_label_idx_combined >= num_labeled] - num_labeled)\n",
    "\n",
    "    return to_label_idx, to_label_idx_unlabeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_accuracy_arr = np.full(num_rounds, np.nan)\n",
    "\n",
    "for i in range(num_rounds):\n",
    "    # Get consensus labels\n",
    "    if i == 0:\n",
    "        consensus_labels = get_majority_vote_label(multiannotator_labels)\n",
    "    else:\n",
    "        # We can use the pred_probs from last round as the best model estimate\n",
    "        results = get_label_quality_multiannotator(\n",
    "            multiannotator_labels, \n",
    "            pred_probs_labeled,\n",
    "            calibrate_probs=True,\n",
    "        )\n",
    "        consensus_labels = results[\"label_quality\"][\"consensus_label\"]\n",
    "\n",
    "    # Train model to get out-of-sample predicted probabilites \n",
    "    pred_probs, pred_probs_unlabeled = fit_predict_proba(\n",
    "        ExtraTreesClassifier(),\n",
    "        X_labeled,\n",
    "        consensus_labels,\n",
    "        cv_n_folds=num_class,\n",
    "        X_unlabeled=X_unlabeled,\n",
    "    )\n",
    "\n",
    "    # Train a model on the full set of labeled data, to evaluate model accuracy for the current round.\n",
    "    # This is optional step for demonstration, you may not have ground truth labels in applications.\n",
    "    model = ExtraTreesClassifier()\n",
    "    model.fit(X_labeled, consensus_labels)\n",
    "    pred_labels = model.predict(X_test)\n",
    "    model_accuracy_arr[i] = np.mean(pred_labels == true_labels_test)\n",
    "\n",
    "    # Compute active learning scores\n",
    "    active_learning_scores, active_learning_scores_unlabeled = get_active_learning_scores(\n",
    "        multiannotator_labels, pred_probs, pred_probs_unlabeled\n",
    "    )\n",
    "\n",
    "    # Get the indices of examples to collect more labels for\n",
    "    relabel_idx, relabel_idx_unlabeled = get_idx_to_label(\n",
    "        active_learning_scores=active_learning_scores,\n",
    "        active_learning_scores_unlabeled=active_learning_scores_unlabeled,\n",
    "        batch_size_to_label=batch_size_to_label,\n",
    "    )\n",
    "\n",
    "    # Format the data for the next round of active learning, moving some unlabeled examples to the labeled pool \n",
    "    # because we are collecting labels for them.\n",
    "    # Note: you need to replace this helper function with your own function to properly update the labeled \n",
    "    # and unlabeled pools in your application.\n",
    "    (\n",
    "        multiannotator_labels, relabel_idx_combined, X_labeled, X_unlabeled, pred_probs_labeled, \n",
    "        pred_probs_unlabeled, extra_labels_labeled, extra_labels_unlabeled,\n",
    "    ) = setup_next_iter_data( \n",
    "        multiannotator_labels, relabel_idx, relabel_idx_unlabeled, X_labeled, X_unlabeled, pred_probs, \n",
    "        pred_probs_unlabeled, extra_labels_labeled, extra_labels_unlabeled,\n",
    "    )\n",
    "\n",
    "    # Collect additional labels for the examples with lowest active learning scores (indices obtained above).\n",
    "    # Here we add one new annotator who labels all of the examples in the selected batch, \n",
    "    # but you could have the existing annotators label these examples instead. \n",
    "    # Note: you need to replace this helper function with your own function to collect additional labels in your application.\n",
    "    multiannotator_labels = add_new_annotator(\n",
    "        multiannotator_labels, extra_labels_labeled, relabel_idx_combined\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the final step of each active learning round above, we added one new annotator that annotates all the examples identified with the lowest active learning scores. It is not required that these examples be labeled by one new annotator (just done here for simplicity). These examples could instead be labeled by multiple new annotators, or multiple existing annotators, or any other combination. However you choose to collect additional labels, just be sure to properly update `multiannotator_labels` to reflect who provided these annotations.\n",
    "\n",
    "Our example above utilized helper functions (eg. `setup_next_iter_data`, `add_new_annotator`) to collect new labels after each round of active learning. You *must* replace these helper functions in real applications with your own code to obtain new labels from human annotators and properly reformat the labeled/unlabeled data with the new labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial model test accuracy: 0.7\n",
      "Final model test accuracy (after 15 rounds of active learning): 0.917\n"
     ]
    }
   ],
   "source": [
    "print(f\"Initial model test accuracy: {model_accuracy_arr[0]:.3}\")\n",
    "print(f\"Final model test accuracy (after 15 rounds of active learning): {model_accuracy_arr[-1]:.3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model_accuracy_arr)\n",
    "plt.xticks(range(num_rounds))\n",
    "plt.xlabel(\"Round\")\n",
    "plt.ylabel(\"Model Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the plot above, we can see that the model accuracy increases steadily with each additional round of collecting more labels, getting improved consensus labels, and model training.\n",
    "To learn about the ActiveLab algorithm and benchmarks of its effectiveness, check out our paper:\n",
    "\n",
    "**[ActiveLab: Active Learning with Re-Labeling by Multiple Annotators](https://arxiv.org/abs/2301.11856)** \n",
    "\n",
    "Beyond the setting demonstrated here (with multiple annotators and unlabeled examples), ActiveLab is also effective for: standard active learning where you just collect at most one label per example (no re-labeling), as well as *active label cleaning* (with no unlabeled pool) where you only want to re-label examples to ensure 100% correct consensus labels (with the least amount of re-labeling)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other useful multiannotator statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After conducting multiple rounds of multi-annotator active learning, you can also estimate various statistics from the labeled data such as the higher quality [CROWDLAB consensus label](https://arxiv.org/abs/2210.06812) for each example, consensus label quality scores that quantify how likely each consensus label is correct, and annotator quality scores that quantify how noisy each annotator's labels are overall. \n",
    "\n",
    "Below we show how to obtain this information using the annotators' labels and the model's predicted class probabilites. Check out cleanlab's [multiannotator module](https://docs.cleanlab.ai/stable/tutorials/multiannotator.html) for details!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the annotator labels and predicted probabilites to get the consensus labels and other statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiannotator_results = get_label_quality_multiannotator(multiannotator_labels, pred_probs_labeled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each row of the `label_quality` dataframe corresponds to an example, here you can get the CROWDLAB consensus label and its quality score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(81, 4)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiannotator_results[\"label_quality\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>consensus_label</th>\n",
       "      <th>consensus_quality_score</th>\n",
       "      <th>annotator_agreement</th>\n",
       "      <th>num_annotations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.693507</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.606298</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.656912</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0.896745</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   consensus_label  consensus_quality_score  annotator_agreement  \\\n",
       "0                1                 0.880000             1.000000   \n",
       "1                2                 0.693507             0.500000   \n",
       "2                2                 0.606298             0.500000   \n",
       "3                1                 0.656912             1.000000   \n",
       "4                2                 0.896745             0.666667   \n",
       "\n",
       "   num_annotations  \n",
       "0                1  \n",
       "1                2  \n",
       "2                2  \n",
       "3                1  \n",
       "4                3  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiannotator_results[\"label_quality\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each row of the `annotator_stats` dataframe corresponds to an annotator, here you can get their annotator quality and other information about the annotators:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotator_quality</th>\n",
       "      <th>agreement_with_consensus</th>\n",
       "      <th>worst_class</th>\n",
       "      <th>num_examples_labeled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.323872</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.378043</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.436048</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.437701</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.448280</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    annotator_quality  agreement_with_consensus  worst_class  \\\n",
       "10           0.323872                  0.333333            0   \n",
       "15           0.378043                  0.500000            1   \n",
       "13           0.436048                  0.500000            0   \n",
       "0            0.437701                  0.428571            1   \n",
       "16           0.448280                  0.666667            2   \n",
       "\n",
       "    num_examples_labeled  \n",
       "10                    12  \n",
       "15                    12  \n",
       "13                    12  \n",
       "0                      7  \n",
       "16                    12  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiannotator_results[\"annotator_stats\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_labeled shape :  (81, 4)\n",
      "X_unlabeled shape :  (9, 4)\n",
      "multiannotator_labels shape :  (81, 17)\n"
     ]
    }
   ],
   "source": [
    "print('X_labeled shape : ',X_labeled.shape)\n",
    "print('X_unlabeled shape : ',X_unlabeled.shape)\n",
    "print('multiannotator_labels shape : ',multiannotator_labels.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "00885e89789f58e60dbba52a405dc834aaf92411914fde0d391f9b48289a0610"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
