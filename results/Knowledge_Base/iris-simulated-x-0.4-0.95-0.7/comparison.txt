{
  "dataset": "iris-simulated-x",
  "data_folder_path": "/Users/kaizer/Documents/Active Learning/Code/MAAL/Multi-Annotator-HIL/datasets",
  "budget_frac": 0.4,
  "boot_size": 0.05,
  "test_size": 0.4,
  "boot_lr": 0.01,
  "boot_n_epochs": 3000,
  "boot_log_epochs": 30000,
  "boot_batchsize": 4,
  "active_lr": 0.02,
  "active_n_epochs": 2000,
  "active_log_epochs": 20000,
  "active_batchsize": 16,
  "hidden_dim": 32,
  "instance_strategy": "random",
  "method": "KB",
  "LR_max_iter": 20000,
  "classifier_name": "logistic_regression",
  "f1_average": "macro",
  "log_dir": "logs/iris-simulated-x/",
  "seed": 1,
  "labeling_type": "max",
  "exp_name": "Trial_1",
  "use_Knowledge_Base": true,
  "similarity_threshold": 0.95,
  "weight_threshold": 0.7,
  "data_source": "mapal",
  "w_opt": 1,
  "rl_flag": 0,
  "ee_ratio": 0.8,
  "Data_path": "/Users/kaizer/Documents/Active Learning/Code/MAAL/Multi-Annotator-HIL/datasets/iris-simulated-x.csv",
  "Path_results": "results/Knowledge_Base/iris-simulated-x-0.4-0.95-0.7",
  "Path_mapal_data": "data_processing/iris-simulated-x-0.4",
  "exp_txt_path": "results/Knowledge_Base/iris-simulated-x-0.4-0.95-0.7/comparison.txt"
}

MAPAL Accuracy : 0.8333333333333334



Number of classes : 3



Fully Supervised
0.96666666666666670.9674603174603175


Total number of Active Learning Instances : 57



Extra instances added due to knowledge base similarity : 23



KNOWLEDGE BASE METRICS

   No. of Instances  Accuracy  f1-score
1                22       1.0       1.0
4                 8       1.0       1.0
3                 5       1.0       1.0
2                12       1.0       1.0
0                 8       1.0       1.0


SIMILAR INSTANCES METRICS

     No. of similar Instances                   Similar Instances  Similar Instances Shared Label  Accuracy  f1-score  Annotator
136                         1                               [109]                               2  1.000000  1.000000          1
121                         1                               [106]                               2  1.000000  1.000000          1
52                          2                            [63, 89]                               1  1.000000  1.000000          1
137                         1                                [83]                               2  0.000000  0.000000          1
143                         1                               [142]                               2  1.000000  1.000000          1
72                          1                                [68]                               0  1.000000  1.000000          1
142                         1                               [101]                               2  1.000000  1.000000          1
82                          2                            [79, 50]                               1  1.000000  1.000000          4
109                         1                               [124]                               2  1.000000  1.000000          3
111                         7  [144, 110, 105, 130, 129, 134, 72]                               2  0.571429  0.242424          2
88                          2                            [70, 61]                               1  1.000000  1.000000          2
147                         1                               [145]                               0  0.000000  0.000000          0
129                         1                               [133]                               2  1.000000  1.000000          0
86                          1                                [97]                               1  0.000000  0.000000          0


ANNOTATOR MODEL PREDICTED LABELS VS TRUE LABELS
Accuracy : 0.8421052631578947
F1 Score : 0.7769230769230768
Confusion Matrix[[ 3  3  1]
 [ 0 22  3]
 [ 0  2 23]]
Classification Report              precision    recall  f1-score   support

           0       1.00      0.43      0.60         7
           1       0.81      0.88      0.85        25
           2       0.85      0.92      0.88        25

    accuracy                           0.84        57
   macro avg       0.89      0.74      0.78        57
weighted avg       0.85      0.84      0.83        57


W OPTIMAL LABELS VS TRUE LABELS
Accuracy : 0.7192982456140351
F1 Score : 0.6873597237637193
Confusion Matrix[[ 3  1  3]
 [ 0 19  5]
 [ 0  7 19]]
Classification Report              precision    recall  f1-score   support

           0       1.00      0.43      0.60         7
           1       0.70      0.79      0.75        24
           2       0.70      0.73      0.72        26

    accuracy                           0.72        57
   macro avg       0.80      0.65      0.69        57
weighted avg       0.74      0.72      0.71        57


MAJORITY LABELS VS TRUE LABELS
Accuracy : 0.7894736842105263
F1 Score : 0.7032746458679818
Confusion Matrix[[ 3  5  3]
 [ 0 22  4]
 [ 0  0 20]]
Classification Report              precision    recall  f1-score   support

           0       1.00      0.27      0.43        11
           1       0.81      0.85      0.83        26
           2       0.74      1.00      0.85        20

    accuracy                           0.79        57
   macro avg       0.85      0.71      0.70        57
weighted avg       0.82      0.79      0.76        57


Compostion of instance and number of queried annotators
[0, 1, 2, 3, 4, 5]
[33, 11, 1, 2, 1, 38]


CLASSIFIER METRICS

                 After Warmup Accuracy on Boot Data  After Warmup F1 Score on Boot Data  After Warmup Accuracy on Validation Data  After Warmup F1 Score on Validation Data  After Training Accuracy on Validation Data  After Training F1 Score on Validation Data
Annotator Model                                1.00                            1.000000                                  0.783333                                  0.765105                                    0.983333                                    0.983701
W Optimal                                      0.75                            0.555556                                  0.650000                                  0.551913                                    0.716667                                    0.723577
Majority                                       1.00                            1.000000                                  0.783333                                  0.765105                                    0.933333                                    0.933977
True Labels                                    1.00                            1.000000                                  0.783333                                  0.765105                                    0.966667                                    0.967460


ANNOTATOR METRIC

                  Annotator Accuracy after Warmup on Boot Data  Annotator F1 Score after Warmup on Boot Data  Annotator Accuracy after Training  Annotator F1 Score after Training
Weighted Average                                           1.0                                           1.0                           0.789474                           0.725214
Maximum Index                                              1.0                                           1.0                           0.824561                           0.763018iris-simulated-x
Budget : 0.4
Similarity Threshold : 0.95
Weight Threshold : 0.7
iris-simulated-x
Budget : 0.4
Similarity Threshold : 0.95
Weight Threshold : 0.7
iris-simulated-x
Budget : 0.4
Similarity Threshold : 0.95
Weight Threshold : 0.7
iris-simulated-x
Budget : 0.4
Similarity Threshold : 0.95
Weight Threshold : 0.7
iris-simulated-x
Budget : 0.4
Similarity Threshold : 0.95
Weight Threshold : 0.7
iris-simulated-x
Budget : 0.4
Similarity Threshold : 0.95
Weight Threshold : 0.7
iris-simulated-x
Budget : 0.4
Similarity Threshold : 0.95
Weight Threshold : 0.7
reports-mozilla
Budget : 0.4
Similarity Threshold : 0.95
Weight Threshold : 0.7
medical
Budget : 0.4
Similarity Threshold : 0.95
Weight Threshold : 0.7
medical
Budget : 0.4
Similarity Threshold : 0.95
Weight Threshold : 0.7
medical
Budget : 0.4
Similarity Threshold : 0.95
Weight Threshold : 0.7
